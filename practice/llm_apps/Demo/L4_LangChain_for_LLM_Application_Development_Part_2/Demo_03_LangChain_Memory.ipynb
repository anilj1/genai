{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "snBYHptMnyJb",
   "metadata": {
    "id": "snBYHptMnyJb"
   },
   "source": [
    "# **Demo: LangChain Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dld3JlxbT53P",
   "metadata": {
    "id": "Dld3JlxbT53P"
   },
   "source": [
    "#__Description:__\n",
    "In this activity, you will learn how to use different types of memory in LangChain. Each type of memory serves a unique purpose and can be used in different scenarios depending on the requirements of your conversation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cVXoe4RUn3O8",
   "metadata": {
    "id": "cVXoe4RUn3O8"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Import the Necessary Modules\n",
    "2. Initialize the Chat Model\n",
    "3. Define ConversationBufferMemory\n",
    "4. Define ConversationBufferWindowMemory with a Window Size of 1\n",
    "5. Define ConversationTokenBufferMemory with a Maximum Token Limit of 30\n",
    "6. Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eyRI2cM0UL1J",
   "metadata": {
    "id": "eyRI2cM0UL1J"
   },
   "source": [
    "# **Step 1: Import the Necessary Modules**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85e3c5a",
   "metadata": {
    "id": "f85e3c5a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cFIuxtHkUTIc",
   "metadata": {
    "id": "cFIuxtHkUTIc"
   },
   "source": [
    "# **Step 2: Initialize the Chat Model**\n",
    "\n",
    "\n",
    "*   Initialize the chat model with a temperature of 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d89f68a-3d5d-4b78-af87-5b0bea28d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from secret_key import openapi_key\n",
    "import os\n",
    "#os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab3e43e",
   "metadata": {
    "id": "3ab3e43e"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1H_MPaTsUZdr",
   "metadata": {
    "id": "1H_MPaTsUZdr"
   },
   "source": [
    "# **Step 3: Define ConversationBufferMemory**\n",
    "\n",
    "\n",
    "*   Utilize it in a ConversationChain for making predictions and printing the memory buffer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32525373",
   "metadata": {
    "id": "32525373",
    "outputId": "94f91c9d-0550-4f10-d677-c75aa61498c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Alex.\n",
      "Human: Add 10 to the above output\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Alex.\n",
      "Human: Add 10 to the above output\n",
      "AI: 4 + 10 equals 14. Is there anything else you would like to know, Alex?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hello, my name is Alex\")\n",
    "conversation.predict(input=\"What is 2+2?\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "conversation.predict(input=\"Add 10 to the above output\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fHKrpuvIUfny",
   "metadata": {
    "id": "fHKrpuvIUfny"
   },
   "source": [
    "# **Step 4: Define ConversationBufferWindowMemory with a Window Size of 1**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c406c55",
   "metadata": {
    "id": "3c406c55",
    "outputId": "dd708430-a4a1-4a89-d140-f144c40bcd9d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: I'm good, thanks\\nAI: Great to hear!\\nHuman: I'm good, thanks\\nAI: Great to hear!\\nHuman: I'm good, thanks\\nAI: Great to hear!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=3)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"How are you?\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.save_context({\"input\": \"I'm good, thanks\"}, {\"output\": \"Great to hear!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a166b0-806a-4ad5-8ee7-e1964384ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is my name?\n",
      "AI: I'm sorry, I do not have access to personal information such as your name. Is there anything else you would like to ask?\n",
      "Human: Add 10 to the above output\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Human: Add 10 to the above output\n",
      "AI: I'm sorry, but I cannot perform mathematical operations on non-numeric values. Is there anything else you would like to know or ask?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k = 1)\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hello, my name is Alex\")\n",
    "conversation.predict(input=\"What is 2+2?\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "conversation.predict(input=\"Add 10 to the above output\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cTgW8BUtvk",
   "metadata": {
    "id": "07cTgW8BUtvk"
   },
   "source": [
    "# **Step 5: Define ConversationTokenBufferMemory with a Maximum Token Limit of 30**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01a67ba",
   "metadata": {
    "id": "e01a67ba",
    "outputId": "7342f887-ab75-4eb9-9b6d-730085ab98fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Machine Learning is what?!\\nAI: Incredible!\\nHuman: Neural Networks are what?\\nAI: Fascinating!\\nHuman: AI Assistants are what?\\nAI: Impressive!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Machine Learning is what?!\"}, {\"output\": \"Incredible!\"})\n",
    "memory.save_context({\"input\": \"Neural Networks are what?\"}, {\"output\": \"Fascinating!\"})\n",
    "memory.save_context({\"input\": \"AI Assistants are what?\"}, {\"output\": \"Impressive!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N5B6Y6g9U15e",
   "metadata": {
    "id": "N5B6Y6g9U15e"
   },
   "source": [
    "# **Step 6: Define ConversationSummaryBufferMemory with a Maximum Token Limit of 100**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713bc684",
   "metadata": {
    "id": "713bc684",
    "outputId": "e781ab8b-d02d-4f2e-b04b-d14a75a82917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human greets the AI and asks what's up. The AI responds that it's working and the human inquires about the agenda for the day.\\nAI: There is a meeting at 10am with your design team. You will need your sketch designs ready. 11am-2pm have time to work on your LangChain project which will go smoothly because Langchain is such a powerful tool. At 2pm, lunch at the sushi restaurant with a client who is flying in to meet you to understand the latest in AI. Be sure to bring your tablet to show the latest LLM demo.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = \"There is a meeting at 10am with your design team. \\\n",
    "You will need your sketch designs ready. \\\n",
    "11am-2pm have time to work on your LangChain \\\n",
    "project which will go smoothly because Langchain is such a powerful tool. \\\n",
    "At 2pm, lunch at the sushi restaurant with a client who is flying \\\n",
    "in to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your tablet to show the latest LLM demo.\"\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"Hello\"})\n",
    "memory.save_context({\"input\": \"What's up?\"}, {\"output\": \"Not much, just working\"})\n",
    "memory.save_context({\"input\": \"What is on the agenda today?\"}, {\"output\": f\"{schedule}\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa1d09e-4276-412c-abf0-9ff036623fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Alex\n",
      "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 2+2?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: Alex introduces himself to the AI, and the AI greets him warmly and asks how it can assist him.\n",
      "Human: What is 2+2?\n",
      "AI: 2 + 2 equals 4. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: Alex introduces himself to the AI, and the AI greets him warmly and asks how it can assist him. The human asks what 2+2 is, and the AI correctly answers 4. When asked for the human's name, the AI does not have that information.\n",
      "AI: I'm sorry, I do not have access to personal information such as your name. How can I assist you with something else?\n",
      "Human: Add 10 to the above output\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[AIMessage(content='The result of adding 10 to 4 is 14. Is there anything else you would like me to help you with?')]\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=40)\n",
    "\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hello, my name is Alex\")\n",
    "conversation.predict(input=\"What is 2+2?\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "conversation.predict(input=\"Add 10 to the above output\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxHfpP_fVBNB",
   "metadata": {
    "id": "uxHfpP_fVBNB"
   },
   "source": [
    "# **Conclusion**\n",
    "You learned how to use different types of memory in LangChain and how to implement and use ConversationBufferMemory, ConversationBufferWindowMemory, ConversationTokenBufferMemory, and ConversationSummaryBufferMemory. You’ve also understood how ConversationSummaryBufferMemory can handle larger pieces of information, such as a daily schedule. This knowledge will help you effectively utilize LangChain’s memory capabilities in your projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2",
   "metadata": {
    "id": "4db224b5-bfba-434e-bf99-f4fb57d924f2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
