{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "briPFNp1Fzpv",
      "metadata": {
        "id": "briPFNp1Fzpv"
      },
      "source": [
        "# __Demo: Tree of Thought Prompting with LangChain and OpenAI__\n",
        "\n",
        "\n",
        "## __Steps to Perform:__\n",
        "Step 1: Set up the OpenAI API Key\n",
        "\n",
        "Step 2: Define a Function to Get Completion\n",
        "\n",
        "Step 3: Define Your Prompts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eAM5-YP-GFdY",
      "metadata": {
        "id": "eAM5-YP-GFdY"
      },
      "source": [
        "### __Step 1: Set up the OpenAI API Key__\n",
        "- Import the required libraries and set up the OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd589c7-3089-4387-801d-443eae67a201",
      "metadata": {
        "id": "edd589c7-3089-4387-801d-443eae67a201"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "#from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "#_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "#openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kfeoI7zTGTCY",
      "metadata": {
        "id": "kfeoI7zTGTCY"
      },
      "source": [
        "### __Step 2: Define a Function to Get Completion__\n",
        "- Construct a message with the user's prompt.\n",
        "- Call the __openai.ChatCompletion.create__ method to get a response from the model.\n",
        "- The temperature parameter is set to __0__ for deterministic (non-random) responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629a2fcb-cffc-4e05-bfc8-429802da7925",
      "metadata": {
        "id": "629a2fcb-cffc-4e05-bfc8-429802da7925"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7sMtUV5hGhjR",
      "metadata": {
        "id": "7sMtUV5hGhjR"
      },
      "source": [
        "### __Step 3: Define Your Prompts__\n",
        "- Provide a series of prompts that guide the model through a tree of thought.\n",
        "- Call __get_completion__ to get a response from the AI model.\n",
        "- Print both the prompt and the AI-generated response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "22ef5cdd-bf0f-4dc3-850b-9ec6fd9f03b7",
      "metadata": {
        "id": "22ef5cdd-bf0f-4dc3-850b-9ec6fd9f03b7",
        "outputId": "3e8bfc1d-b759-413e-c40f-1aae50831243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_completion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2ba7a985390d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mConsidering\u001b[0m \u001b[0mthese\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreason\u001b[0m \u001b[0mout\u001b[0m \u001b[0mon\u001b[0m \u001b[0mown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthen\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI Response:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_completion' is not defined"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Solve the problem: A farmer has 100 meters of fencing and wants to enclose the maximum area for his rectangular field. What should the dimensions be?\n",
        "\n",
        "Let's think about this in a few ways:\n",
        "\n",
        "1. If the field is a square, each side would be 100 / 4 = 25 meters. The area would be 25 * 25 = 625 square meters.\n",
        "\n",
        "2. What if the field is not a square? Let's try a 4:1 ratio. The lengths would be 40 and 10 meters. The area would be 40 * 10 = 400 square meters.\n",
        "\n",
        "3. Are there any other ratios that might give a larger area than a square or a 4:1 rectangle?\n",
        "\n",
        "Considering these options and reason out on own and then output the best dimensions for the maximum area :\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Let's analyze the legal case by considering multiple precedents and possible outcomes.\n",
        "\n",
        "1. Precedent 1: A similar case where the plaintiff won.\n",
        "    - Branch A: The court found that the defendant was negligent.\n",
        "        - Sub-branch A1: The plaintiff was awarded damages due to clear evidence of negligence.\n",
        "        - Sub-branch A2: The court ruled in favor of the plaintiff due to the defendant's breach of duty.\n",
        "\n",
        "2. Precedent 2: A similar case where the defendant won.\n",
        "    - Branch B: The court found no negligence on the defendant's part.\n",
        "        - Sub-branch B1: The plaintiff failed to provide sufficient evidence.\n",
        "        - Sub-branch B2: The court ruled that the plaintiff assumed the risk.\n",
        "\n",
        "3. Precedent 3: A case with a mixed outcome.\n",
        "    - Branch C: The court found both parties partially at fault.\n",
        "        - Sub-branch C1: Damages were reduced based on the plaintiff's contributory negligence.\n",
        "        - Sub-branch C2: The court ruled that both parties shared liability, resulting in a split decision.\n",
        "\n",
        "4. Based on the facts of the current case, consider the most likely outcome.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "zIj09kIO9lkE"
      },
      "id": "zIj09kIO9lkE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\"You have 12 identical-looking balls, but one is either heavier or lighter.\n",
        "You have a balance scale and can only use it three times.\n",
        "Think step-by-step, and at each step, explore multiple possible ways to proceed.\n",
        "Evaluate which options are promising and continue expanding those paths.\n",
        "Discard any unhelpful paths. After exploring the reasoning tree, provide the best solution.\"\n",
        "\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "puIisSS1-MHf"
      },
      "id": "puIisSS1-MHf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Let's plan a weekend trip by considering multiple options.\n",
        "\n",
        "1. Option 1: Go to the mountains.\n",
        "    - Branch A: If the weather is good in the mountains.\n",
        "        - Sub-branch A1: You can go hiking.\n",
        "        - Sub-branch A2: You can visit a nearby lake.\n",
        "    - Branch B: If the weather is bad in the mountains.\n",
        "        - Sub-branch B1: You will stay in a cabin and relax.\n",
        "        - Sub-branch B2: You can explore local museums.\n",
        "\n",
        "2. Option 2: Go to the beach.\n",
        "    - Branch C: If the weather is sunny at the beach.\n",
        "        - Sub-branch C1: You can swim in the ocean.\n",
        "        - Sub-branch C2: You can sunbathe and play beach volleyball.\n",
        "    - Branch D: If the weather is cloudy or rainy at the beach.\n",
        "        - Sub-branch D1: You will visit indoor attractions like an aquarium.\n",
        "        - Sub-branch D2: You can go shopping in beachside stores.\n",
        "\n",
        "3. Considering all these factors, decide the best option for your weekend trip.\n",
        "\n",
        "What should i do for my trip to Goa in month of august\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "8mMT-V9o-QBg"
      },
      "id": "8mMT-V9o-QBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f1ffIbSSFx-S",
      "metadata": {
        "id": "f1ffIbSSFx-S"
      },
      "source": [
        "\n",
        "Analyze the output of the model. If the output is not satisfactory, you can refine the prompts and repeat the process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 [3.10]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}